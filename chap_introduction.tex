\chapter{Introduction}
\label{chap:introduction}

\section{Motivation}
The last few decades have seen the most pronounced technology evolution in history, in many different research areas and consumer markets: from robotics to smartphones, from medicine to the automotive industry, etc. One of the pillars upon which all these advancements have been made possible is the Internet, or more generally the entire set of networking technologies that allow software to communicate.


The process towards interconnected devices saw a big leap forward in the early 1960s with the first research into packet switching as an alternative to the old circuit switching. But it is 1981 the year of standardization for the TCP/IP protocol suite \cite{rfc793}, which permitted the expansion of interconnected networks. The Internet grew rapidly, passing from a few tens of million users in the 1990s to almost 3 billions users in 2014, as shown in figure \ref{fig:internet_growth} \cite{internetlivestats}. Even more impressive is the number of networked devices and connections globally: around 14 billion in 2014 \cite{cisco}.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{images/internet_growth}
\caption{The expansion of the Internet}
\label{fig:internet_growth}
\end{figure}

``Network'' is a very generic term. In the IT context, a computer network is set of connected nodes adopting common protocols to exchange data. The most widespread protocol for networking communication is the above-mentioned TCP/IP protocol, that is used in the vast majority of services like the World Wide Web, email, file transfer, remote system access, etc. It is also often used as a communication protocol in private networks and data centers.
The reason for its wide adoption is not that there aren't good alternatives: TCP/IP is not to most performing protocol in every network environment, but it is relatively simple and it introduces fairly low complexity in the overall architecture, still meeting all the most common security and reliability requirements. Back in the 1980s, TCP/IP was the simpler way for applications to use most networks and eventually it was chosen as the protocol for the Internet, thus quickly becoming a de-facto standard \cite{computerworld}.

During its life, the TCP/IP protocol suite has been improved with various updates and additional components to reach the desired levels of network congestion, traffic load balancing, handling of unpredictable behaviors, security, user-experience and so on. Such aspects became more and more challenging with the uncontrollable expansion of the Internet.
Albeit, after all the years that passed since the first implementation, the core components of the TCP/IP protocol design haven't changed at all, mainly for backward compatibility reasons. This inevitably causes some aspects of the old protocol to look very limited in the current networking reality. A well known example is the scarcity of available IPv4 addresses: when TCP/IP was designed in the early stages, a 32-bit number seemed to be a very high number to encompass all the users of the network. Nevertheless, due to the unexpected increase rate in the number of Internet users (and also due to inefficient IP allocation policies), the available IPv4 addresses run out quickly, forcing the introduction of the lengthy 126-bit address format, known as IPv6, formalized in 1998 \cite{rfc2460}. IPv6 is intended to replace IPv4, but the transition towards the new format turned out to be a remarkably complicated procedure overall: IPv6 is not designed to be directly interoperable with IPv4, and even if nowadays the majority of the systems are IPv6-compatible, it took about 20 years to reach the current percentage of overall adoption: 10\% (percentage of IPv6 users accessing Google \cite{google}). This should be a good indicator of the big challenge that is modifying the core design aspects of the TCP/IP architecture, a recurrent topic in this paper.

When the TCP protocol was first developed in the 1970s, it was certainly difficult to predict the rate of growth of the networks around the globe, not only in terms of the number of nodes involved, but also in terms of the quantity and type of the transmitted data, the increasing need of low latency for new streaming applications, the advancement in the hardware adopted to carry the data and the computing power of the interconnected devices. Today we can count billions of interconnected devices, and we have just started the era of the IoT (Internet of Things) which aims at giving communication capabilities to virtually every object commonly used in our daily life.
As a result of this process, the networks are becoming more complex and devices often use multiple interfaces to stay connected. Common appliances like smartphones provide both cellular connectivity and Wi-Fi modules (figure \ref{fig:smartphones}); same technologies can be often found in tablets; laptops have at least Wi-Fi capabilities plus an Ethernet port, and they support third-party receivers for connectivity through cellular networks. The argumentation is much more complex in the backend infrastructures' scenario, which is rapidly evolving due to a new interest in BigData storage and analysis, as well as the flourishing of wide-scale low-latency streaming services (video streaming, VoIP, multiplayer videogames, etc.). Data centers often count tens of thousands of interconnected nodes, often including content-delivery servers that are capable of handling a high number of connections simultaneously.

\begin{figure}[!htb]
\centering
\includegraphics[width=0.75\textwidth]{images/smartphones}
\caption{The typical smartphone connectivity}
\label{fig:smartphones}
\end{figure}

The implications of this new reality include the possibility of establishing multiple paths to transmit data between two applications running on the communicating hosts, since they are now often equipped with multiple network interfaces, each configured with an active IP address. Back in 1970s, TCP was designed to create a virtual connection between exactly two IP addresses and two port values, with almost no flexibility or dynamism in address/port addition and removal within the duration of the connection. In the multipath reality of the infrastructures of today, to old point-to-point single-path connection provided by TCP looks quite limiting. This led to various projects aiming at exploiting the multipath concept, and Multipath TCP is one of them.


Multipath TCP (MPTCP) is an ongoing project managed by the Internet Engineering Task Force (IETF), whose specifications have been published as Experimental Standard in January 2013 \cite{rfc6824}; such protocol extends the current TCP to introduce multipathing capabilities, maintaining backward compatibility at the endpoints and undertaking a major endeavor to avoid disrupting of middleboxes' behavior. MPTPC can communicate with the application layer via standard TCP interface and it automatically splits data at the sender, it sends the data through different subflows (each being basically a regular TCP connection) according to the IP addresses and interfaces available at the hosts and finally reassembles the data at the receiver, in fact enabling multipathing.

\subsection{Benefits of MPTCP}
\label{benefits}
Multipathing provides hosts with the resource pooling concept applied to networking access. Resource pooling allows dynamism and flexibility in requesting and handling resources and it is a positive trend in many services and architectures: Content Delivery Networks (CDNs), Peer-to-Peer (P2P) networks, Cloud Computing, etc. The very concept of packet switching, the core aspect of the modern Internet, is based on a resource pooling technique: circuit utilization is no more performed by allocating isolated channels in the link (static multiplexing) as it was the case with circuit switching, but the traffic is fragmented into small addressed packets that can share the overall link capacity (statistical multiplexing) \cite{DBLP:journals/corr/QadirAYSC15}. MPTCP aims at taking this concept to the next level, by grouping a set of separate links into a pool of links (figure \ref{fig:pooling}).


\begin{figure}[!htb]
\centering
\includegraphics[width=0.75\textwidth]{images/pooling}
\caption{MPTCP pooling principle}
\label{fig:pooling}
\end{figure}


The benefits include better resource utilization, better throughput and smoother reaction to failures, leading to an overall improved user experience, as shown in the following four major use-cases:
\begin{itemize}
  \item Combining MPTCP multipath and multihoming\footnote{Multihoming: the connection to the Internet via multiple providers.}, it is possible to achieve higher throughput by exploiting multiple simultaneous connections to transfer different portions of the same piece of data. For example, a typical smartphone could use its cellular module and its Wi-Fi module simultaneously in downloading a file from a remote server, despite them having two different IP addresses;
  \item It is possible to introduce failure handover for the connection with no special mechanism at network or link layer. If one of the interfaces stops working or the flow of data gets interrupted for any reasons, data transfer can seamlessly continue through other interfaces;
  \item By assigning different priorities to the various flows, it is possible to better handle data transfer through the different interfaces. This could be useful if some connectivity modules drain more battery than others, or if some interfaces are associated to a limited capacity data plan. For example, let's consider the case of a file download on a smartphone via 4G connectivity: it would be advantageous to seamlessly switch the whole data transfer to the Wi-Fi interface if that becomes available in the middle of the download, starting from the point left by the cellular connection and without the need to restart the session;
  \item Providing multipath awareness to current network stacks can improve load balancing and exploitation of the network resources in data centers; this is a valuable aspect, considering that the network performance in data centers is usually critical for maintaining low latency for the overall system. A similar concept applies to load balancing in ISPs' network backbones.
\end{itemize}

\subsection{Multipathing solutions}
\label{mptcp_alternatives}
MPTCP aims at achieving all the benefits mentioned in the previous paragraph by operating at the transport layer of the traditional Internet architecture (the OSI model\footnote{Open System Interconnection model produced at the International Organization for Standardization (ISO): standard model to abstract the communication system of computer networks into different layers of operation without referencing any specific protocol and implementation \cite{osi}.} is shown in figure \ref{fig:OSI}), which is the same layer in which TCP operates.
Before MPTCP, other proposals have been elaborated to achieve multipath benefits by introducing new technologies at the link layer, network layer and transport layer as well. Even at the application layer, developers can create custom frameworks on top of TCP to achieve benefits similar to those that would come by exploiting multipath natively at the lower layers. For example, most modern browsers open many TCP connection simultaneously to download the various elements of a Webpage to improve user experience \cite{Yuchung}. Another example could be Skype and similar VoIP services, which try to automatically reconnect hosts in case of problems with minimum impact on the user experience. Albeit all the solutions at the application layer are just clever workarounds on top of regular TCP and they fall only marginally into our discussion regarding multipath.

\begin{figure}[!htb]
\centering
\includegraphics[width=0.75\textwidth]{images/OSI}
\caption{The traditional Internet architecture (OSI model)}
\label{fig:OSI}
\end{figure}

The following list gives a general overview of the most important multipathing solutions other than MPTCP, grouped according to the architectural layer they operate in:
\begin{itemize}
  \item \textit{Link layer}: there are different ways to achieve resource pooling through link aggregation at link layer, but the basic concept is to setup multiple physical links between two logical devices (for example a server and the next-hop switch, or two switches) so that they are bundled in a single \textit{Link Aggregate Group} (LAG) transparently to the higher-level applications. In order for this to work, proper configuration is needed at both the endpoints of the aggregated link, even if a protocol named LACP has been standardized in order to achieve automation in link aggregation configurations \cite{thenetworkway}. It is important to notice that the single data flows are still sent to a single link in the LAG pool in order to maintain sequence-ordering, but overall bandwidth available for all data flows is increased and failover mechanism is really quick and efficient \cite{thenetworkway}. Despite being a common solution in ISPs' inner infrastructure and data centers to improve the bandwidth in specific portions of the network, end users usually cannot directly take advantage of this technology;
  \item \textit{Network layer}: there exist multiple solutions to better exploit multipathing at this layer, most notably \textit{Mobile IP} \cite{rfc5944} and \textit{Shim6} \cite{rfc5533}. Without going into the details, they both provide hot-handover capabilities with no interruption of the higher-level services, with some limitations: Mobile IP requires extensive support by the underlying infrastructure and Shim6 is an IPv6 only solution. More importantly, there is a fundamental problem in confining resource pooling at the network layer: TCP operates at the transport layer but it is closely related to the network layer because it statefully inspects various properties of the underlying network paths to provide performance optimizations (this is why referring to TCP often implies taking into consideration the whole TCP/IP protocol stack): this means that in most cases transparent modifications at the network layer would cause TCP malfunctioning;
  \item \textit{Transport layer}: the most notable experiment in multipath exploitation prior to MPTCP is the Stream Control Transmission Protocol (SCTP) \cite{rfc4960}. Such protocol is, in many ways, similar to MPTCP: the first version of SCTP provided failover capabilities by exploiting different interfaces, and successive versions introduced multi-streaming capabilities to increase throughput. The major problem with SCTP is that it was thought to be an independent, enhanced version of TCP, and the two protocols are indeed incompatible with each other. This means that a wide adoption of SCTP would require to upgrade the networks to be SCTP aware. Moreover, all the applications would need to be upgraded to explicitly switch to the new protocol for communication. The vast global networking scenario of today, mainly based on TCP, makes these requirements virtually impossible to meet, and SCTP remains a technology of very limited adoption \cite{ipspace}.
\end{itemize}

All these previous solutions didn't get widespread adoption. Link layers and network layers solutions require extensive modifications in the underlying network configurations in order to achieve the desired results; introducing a totally new multipath-aware protocol at the transport layer requires to change all the applications in order for them to communicate over the new protocol, thus allowing this solution in very limited scenarios; workarounds at the application layer, despite being quite effective, are far from the purpose of MPTCP.

MPTCP primary goal is to automatically introduce multipath to the infrastructures and devices currently adopting TCP, with the minimum possible effort from users, developers and network maintainers. Engineers decided that the best way to achieve all these requirements was to still use TCP as fundamental block for communication, extending it to support multipath: the entire protocol design works by adding MPTCP custom options into regular TCP segments and each subflow in MPTCP is indeed seen by the lower infrastructure as a regular TCP connection.
MPTCP got a lot of attention in the Internet community in the last few years, and many consider MPTCP as a valuable step forward for the whole global network currently relying on TCP.
The final goal of MPTCP is to replace the majority of the current TCP implementations, which is a very delicate process in which all the current TCP standards in terms of robustness, performance and security have to be maintained, if not improved. This paper is an evaluation of the security aspects of MPTCP, with an analysis of current threats and vulnerabilities affecting the protocol.

\section{Problem statement}
MPTCP is a big effort from the IETF to unlock multipath networking capabilities worldwide, with many subtle implications for current infrastructures. Hence the importance of evaluating the current security status of MPTCP, by inspecting its implications on external middleboxes and security equipment and also by analyzing internal design flaws that might allow attacks to the MPTCP sessions.
The reference implementation for the new protocol is available for the Linux Kernel and currently maintained in an off-tree open-source repository.
The main focus of this paper is related to the main vulnerability currently known for the protocol, concerning the ADD\_ADDR component: during the thesis work such vulnerability is studied and the solution for it is implemented and evaluated. In the process, patches for the Linux Kernel implementation of the protocol have been developed to fix the vulnerability and mark the first step towards the Linux implementation of the new version of MPTCP. The afore-mentioned vulnerability, present in the version 0 of MPTCP, can potentially allow an attacker to perform an off-path hijacking of the connection by exploiting the ADD\_ADDR functionality of advertising the creation of a new subflow: in very simplified terms, the attacker would be able to advertise its own IP address to execute the hijacking.

A comprehensive list of all the objectives for the thesis work is the following:
\begin{itemize}
    \item Studying the security implications of adopting MPTCP on current infrastructures;
    \item Listing the known vulnerabilities affecting the current version of the protocol;
    \item Studying and exploiting the ADD\_ADDR vulnerability of the protocol;
    \item Evaluating the possible solutions for the ADD\_ADDR vulnerability;
    \item Assessing the best solution for the ADD\_ADDR vulnerability and developing it for the Linux Kernel implementation of MPTCP;
    \item Developing effective and powerful simulation scenarios in order to test MPTCP (and possibly other networking protocols);
    \item Contributing to the upstreaming of MPTCP into the Linux Kernel by developing patches and contributing to official RFC documentation.
\end{itemize}

\section{Methodology}
The thesis work has been carried out at the Intel Corporation offices in Lund (Sweden). The process took six months in total, with a main focus on testing and developing. The entire work has been closely followed by major stakeholders in the MPTCP community, located in Sweden, Romania and the United States. Such cooperation involved patch reviewing and weekly meetings.

The engineering approach adopted for the thesis work involved a first major step (phase 1) regarding observations on the protocol's behaviour when subjected to external custom-made input. This step can be considered per se a smaller and modular sub-project, in which it is possible to define yet other sub-steps:

\begin{itemize}
    \item Setting up and running standard MPTCP connections on a portable virtual environment that is fast to manipulate and that provides all the means to allow monitoring and testing of the connections. Such environment had to provide tracing and debugging capabilities for the running Kernel images as well;
    \item Evaluating (or developing) proper external tools to monitor and capture all the low-level details of the packets exchanged during the MPTCP sessions;
    \item Evaluating (or developing) proper external tools to efficiently operate on the ongoing MPTCP sessions, by manipulating and injecting forged packets. Other ways to operate over the connections have been taken into consideration, including firewall configurations necessary to block specific kind of packets.
\end{itemize}

These preliminary steps allowed to obtain a fundamental test-bed configuration later adopted extensively during the whole development phase. 
The development phase (phase 2) consisted on a different methodology approach involving multiple iterations. Each iteration consisted on:

\begin{itemize}
    \item Examining the specifications for the required features under development; if present, closely investigate the review and feedbacks from external sources on the ongoing iteration;
    \item Applying a relatively small amount of changes to the current MPTCP implementation according to the previous step;
    \item Extensively testing all the regular behaviors and edge cases potentially affected by the modifications elaborated in the previous step (by using the tools from phase 1);
    \item Restarting the loop from the first step in case of malfunctioning due to bug in the code; otherwise, changes were pushed into experimental repositories for external evaluations, reviews and feedbacks.
\end{itemize}

Despite the iterative approach, the development phase have been arranged to keep good levels of modularity in the produced code, so that each elaborated feature required a certain number of iterations to be completed but the final result could be considered self-contained and valid for all the subsequent features built on top of it. 
Such modularity translated in practice into a number of different patches for the Linux Kernel implementation of MPTCP; this allowed for easy selection of the components valuable for the official implementation, while others were saved in experimental branches for future reference.
Each one of the MPTCP features have been developed starting from the specifications and comments from external sources, but the collaborative working environment with the other stakeholders involved in the project allowed to occasionally reverse the operational flow and propose more or less formal modifications regarding the protocol's functioning, according to unexpected needs that showed up during the implementation work.
The entire set of iterations and the final patches' submission were followed by a high-level evaluation of the work in its entirety, meaning that all the produced code considered for merging were externally reviewed. This process brought up minor issues and subsequent faster fixes until the final product was deployed, i.e. all the patches (merged and experimental) were finalized. 

A last major step in the methodology for the work consisted in writing the final report. During such last step (phase 3), an experimental evaluation on the overall product has been developed to provide additional insights on the performance and functioning changes introduced with the new patches. It is important to mention that no modifications have been applied to the final patches during this phase, since the correct functioning has been positively certified at the end of the development phase and the merging has been already issued at this time, but the additional tests were developed to gather additional data mainly on performance impact due to the introduced modifications regarding ADD\_ADDR functioning; as a single exception, the experimental evaluation process made it possible to find a bug in one of the merged patches, meaning that a smaller bug-fix code change has been merged into the official MPTCP repository during the last phase of the work.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{images/methodology}
\caption{The adopted engineering methodology}
\label{fig:methodology}
\end{figure}

\subsection{Daily workflow}
The workflow started with an overall study of MPTCP and how it interacts with the most common middleboxes. The next step was a more focused evaluation of the current threats for the protocol, mainly referencing to the RFC document regarding such topic \cite{rfc7430}. Within the document, only one vulnerability is considered a blocking issue in the advancement of MPTCP standardization, known as the ADD\_ADDR vulnerability. The document also proposes a change in the protocol design that fixes the problem. With such background, the actual development stage of the work started. At first, it was necessary to sync with the development status by interacting with the official MPTCP mailing list for developers, at \url{https://listes-2.sipr.ucl.ac.be/sympa}. This allowed to make sure that the ADD\_ADDR solution proposed in official documentation \cite{rfc7430} was indeed the preferred one and that nobody started developing a patch for it already.
Before starting to work on the fix, a first stage of the work involved a deeper analysis of the ADD\_ADDR vulnerability: a connection hijacking has been executed by exploiting such vulnerability in a testing environment. This allowed to better validate the criticality of the problem and it was a useful experiment to get acquainted with MPTCP. Moreover, it was a good way to setup a proper testing environment that was then used during the whole patch-development process that followed.

The entire code developed during the stage, around 400 line additions, was eventually merged into the official MPTCP repository for the Linux Kernel. Some additional contributions have been performed in order to improve RFC documentation about the protocol and to upgrade related networking tools to be compatible with the new version of MPTCP.

\subsection{Document structure}
The structure of this paper mainly follows the workflow explained in the previous section. After the introductory first chapter, the discussion is mainly subdivided into two parts: a first part with an analysis about MPTCP background and working principles (chapters 2 and 3); a second part about the original work on simulating and fixing the ADD\_ADDR vulnerability (chapters 4 and 5):

\begin{itemize}
  \item Chapter 2 starts with a broad explanation of the basic concepts of TCP to introduce how MPTCP has been developed on top of it. All the technical details of the new protocol can be found in this chapter, that also includes an analysis on the MPTCP deployment status in the real world and the problematics associated in upstreaming the protocol (mainly incompatibilities with current middleboxes);
  \item Chapter 3 is again a background analysis on MPTCP, with a narrowed focus on security. The chapter includes a comprehensive threats analysis, with an overview of the current security issues affecting the protocol. An entire section is dedicated to the ADD\_ADDR vulnerability. In such section all the details regarding the vulnerability are presented: how to exploit it to hijack an MPTCP connection and what are the requirements  an attacker needs to execute the attack;
  \item Chapter 4 is the first part that introduces the original work carried out during the thesis work. Taking as reference the theory behind the ADD\_ADDR attack explained in the previous chapter, this section explains the development of the script capable of exploiting the vulnerability in a simulated environment. The script code is explained step-by-step, as well as the entire procedure to setup the virtual machines to execute the attack. This entire chapter aims at validating the criticality of the ADD\_ADDR vulnerability and in doing so it also provide setup guidelines for a powerful simulating environment that can be useful for future MPTCP testing and development;
  \item Chapter 5 contains the core part of the thesis work. It starts with a theoretical evaluation of the accepted fix for the ADD\_ADDR vulnerability and it proceeds with its development for the Linux Kernel implementation of MPTCP. All the issues encountered during the project, as well as the required side-features that needed to be implemented for proper functioning, are reported in this chapter. The two last sections of this chapter sum up the contributions produced during the thesis work and provide final evaluation of the performance of the produced patches;
  \item Chapter 6 is the conclusive part of the paper, where related work and proposals for future work are present.
\end{itemize}
